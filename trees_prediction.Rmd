---
title: "Untitled"
author: "VV"
date: "04 10 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(quanteda)
library(stringr)
library(caret)

#twitter.coded <- read_csv("http://maslinsky.spb.ru/courses/cmta2017/data/full_corpus_done_for_seminar.csv")
twitter.coded <- read_csv("~/тексты/full_corpus_done_for_seminar.csv")
set.seed(13)

rus_sentiments <- read_csv("~/russian-twitter/rus_sentiments.csv",  comment="#") 
names(rus_sentiments) <- c('word', "type_of_speech", "lemma", "sentiment", "source", "ambiguity")

dtm <- twitter.coded$all_tweets %>% str_replace_all('@[a-zA-Z0-9_]+', "@user") %>% tokens(what="word", remove_numbers=TRUE, remove_punct=FALSE, remove_separators=TRUE) %>% dfm 
## стемминг, отбрасывание слов с частотностью меньше 10, взвешивание (опционально)
dtm <- dtm %>% dfm_wordstem(language = "ru") %>% dfm_trim(min_docfreq=0.05) %>% as.data.frame #%>% dfm_weight(type="relmaxfreq") 

looong <- str_count(twitter.coded$all_tweets, "\\w*([a-яА-Я])\\1\\1+\\w*") ##слова с удл. гласными
#looong_punct <- str_count(twitter.coded$all_tweets, "\\w*([[]])\\1\\1+\\w*") ##слова с удл. гласными

twitter.coded$clean <- str_to_lower(twitter.coded$all_tweets) #нижний регистр
twitter.coded$clean <- str_replace_all(twitter.coded$clean , "@[[:word:]]+", "USERID") #заменить mentions
twitter.coded$mentions <- str_count(twitter.coded$clean, "USERID") %>% as.numeric()  #количество mentions -- в идеале хорошо бы уникальных посчитать))

twitter.coded$clean <- str_replace_all(twitter.coded$clean , "http[[:graph:]]+", "LINK") #заменить сслылки
twitter.coded$num_posts <- str_count(twitter.coded$clean, "\n") %>% as.numeric() + 1 #количество твитов пользователя

twitter.coded$clean <- str_replace_all(twitter.coded$clean, "#", "HASHTAG")
twitter.coded$hashtags <- str_count(twitter.coded$clean, "HASHTAG") %>% as.numeric()  #количество хэштегов

twitter.coded$clean <- str_replace_all(twitter.coded$clean, "[[:punct:]]", " ")
twitter.coded$clean <- str_replace_all(twitter.coded$clean, "HASHTAG", "#")

twitter.coded$clean <- str_replace_all(twitter.coded$clean, "[[:digit:]]", " ")
twitter.coded$clean <- str_replace_all(twitter.coded$clean, "<br/>", " ")

twitter.coded$clean <- str_replace_all(twitter.coded$clean, '\\p{So}|\\p{Cn}', '')
#не учитываются смайлы и другие знаки пунктуации
twitter.coded$clean <- str_replace_all(twitter.coded$clean, '[[:space:]]+', ' ')

#twitter.coded$clean[1]

#[:upper:]

#sentiment <- stringr::str_count(twitter.coded$clean[1], rus_sentiments$word[rus_sentiments$sentiment=="positive"] %>% paste(collapse = "|")) 


sentiment2 <- twitter.coded$clean %>% map(~ stringr::str_count(.x, rus_sentiments$word[rus_sentiments$sentiment=="positive"] %>% paste(collapse = "|"))) 
twitter.coded$positives = sentiment2

sentiment3 <- twitter.coded$clean %>% map_dbl(~ stringr::str_count(.x, rus_sentiments$word[rus_sentiments$sentiment=="negative"] %>% paste(collapse = "|"))) 

sentiment30 <- sentiment3 %>% unlist()
twitter.coded$negatives = sentiment30 %>% as.numeric()

sentiment4 <- twitter.coded$clean %>% map_dbl(~ stringr::str_count(.x, rus_sentiments$word[rus_sentiments$sentiment=="neutral"] %>% paste(collapse = "|"))) 
sentiment40 <- sentiment4 %>% unlist()
twitter.coded$neutral = sentiment40%>% as.numeric()

sentiment5 <- twitter.coded$clean %>% map(~ stringr::str_count(.x, rus_sentiments$word[rus_sentiments$sentiment=="positive/negative"] %>% paste(collapse = "|"))) 
sentiment50 <- sentiment5 %>% unlist()
twitter.coded$positive_negative = sentiment50 %>% as.numeric()

sentiment0 <-  dplyr::select(twitter.coded, positives, negatives, neutral, positive_negative) %>% rowSums()

twitter.coded$sentiment_found = sentiment0

write_csv(twitter.coded, "~/russian-twitter/twitter.coded.csv")

dtm.extended <- cbind(looong=looong, twitter.coded %>% select(num_posts:positive_negative), dtm) %>% as.data.frame

```


##Test and train 
```{r}
dtm.extended_punct = dtm.extended[str_detect(names(dtm.extended), "[[:punct:]]")]
dtm.extended = dtm.extended[!(str_detect(names(dtm.extended), "[[:punct:]]"))]
names_punct = names(dtm.extended_punct)
names(dtm.extended_punct) = paste("punct", 1:45, sep = "")
dtm.extended = cbind(dtm.extended, dtm.extended_punct)





split <- createDataPartition(y=twitter.coded$age, p = 0.9, list = FALSE)
train.data <- dtm.extended[split,]
test.data <- dtm.extended[-split,]
train.df <- twitter.coded[split,]
test.df <- twitter.coded[-split,]

```

## Gender prediction
```{r}
#names(getModelInfo())

## параметры обучения: 10-fold кросс-валидация
ctrl <- trainControl(method="cv", 4, verboseIter=TRUE)

#model.lr <- train(train.data, train.df$sex, method="glmnet", family="binomial", trControl=ctrl)

df_sex = cbind(sex = train.df$sex, train.data) 
df_stage = cbind(sex = train.df$life_stage, train.data) 

fit.ctree <- train(sex ~ ., data = df_sex, method='ctree', trControl=ctrl)
fit.ctree

#plot(fit.ctree)
ctreeVarImp = varImp(fit.ctree)


## логистическая регрессия
predicted <- predict(fit.ctree, newdata=train.data)
cm.lr <- confusionMatrix(data = predicted.sex.lr, reference = test.df$sex, positive="ж")
cm.lr
varImp(model.lr)



#############
library(rpart)
tree <- rpart(Admission_YN ~ adm_data$Grad_Rec_Exam + adm_data$Grad_Per+ adm_data$Rank_of_col, data=adm_data,  method="class")

plot(tree)
text(tree, pretty=0)
library(rpart.plot)
fancyRpartPlot(tree)

printcp(tree)
plotcp(tree)

ptree<- prune(tree, cp= tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
fancyRpartPlot(ptree, uniform=TRUE, main="Pruned Classification Tree")

```

random forests
```{r}
library(randomForest)

```

[](https://www.r-bloggers.com/random-forests-in-r/) 
